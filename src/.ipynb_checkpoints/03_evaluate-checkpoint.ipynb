{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Daniel Yang/Desktop/Final_Project\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import glob\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileId_path = \"experiments/fileIds.pkl\"\n",
    "queryInfo_path = \"experiments/queryInfo.pkl\"\n",
    "timeData_path = \"experiments/timeData.pkl\"\n",
    "audioFiles_path = \"experiments/audioFiles.pkl\"\n",
    "with open(fileId_path, 'rb') as f:\n",
    "    fileIds=pkl.load(f)\n",
    "with open(queryInfo_path, 'rb') as f:\n",
    "    queryInfo=pkl.load(f)\n",
    "with open(timeData_path, 'rb') as f:\n",
    "    timeData=pkl.load(f)\n",
    "with open(audioFiles_path, 'rb') as f:\n",
    "    audioFiles=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readHypFiles(hypdir):\n",
    "    data = []\n",
    "    for hypfile in sorted(glob.glob(\"experiments/{}/*.hyp\".format(hypdir))):\n",
    "        print(hypfile)\n",
    "        with open(hypfile, \"rb\") as f:\n",
    "            data.append(pkl.load(f))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSegmentLevel(segment_predict, solo_name, ref_name, sr=22050):\n",
    "    pieceName = solo_name.split('_')[0]\n",
    "    gt_segments = queryInfo[pieceName]\n",
    "    gt_samples = []\n",
    "    diffs = []\n",
    "    for beats in gt_segments:\n",
    "        beat1 = beats.split(',')[0][1:]\n",
    "        beat2 = beats.split(',')[1][:-1]\n",
    "        sample1 = timeData[ref_name][beat1]*512\n",
    "        sample2 = timeData[ref_name][beat2]*512\n",
    "        gt_samples.append((sample1, sample2))\n",
    "    for idx,segment in enumerate(segment_predict):\n",
    "        seg0 = segment[0]\n",
    "        seg1 = segment[1]\n",
    "        diff0 = np.abs(gt_samples[idx][0]-seg0)/sr\n",
    "        diff1 = np.abs(gt_samples[idx][1]-seg1)/sr\n",
    "        diffs.append(diff0)\n",
    "        diffs.append(diff1)\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDiffLevel(tf, segment_predict, solo_name, ref_name, sr=22050):\n",
    "    # Only evaluate within segments\n",
    "    diffs = []\n",
    "    beat_ls = []\n",
    "    pieceName = solo_name.split('_')[0]\n",
    "    gt_segments = queryInfo[pieceName]\n",
    "    annotated_beats = list(timeData[ref_name].keys())\n",
    "    beat_array = []\n",
    "    for beats in gt_segments:\n",
    "        beat1 = beats.split(',')[0][1:]\n",
    "        beat2 = beats.split(',')[1][:-1]\n",
    "        idx1 = annotated_beats.index(beat1)\n",
    "        idx2 = annotated_beats.index(beat2)\n",
    "        base_time = tf[int(timeData[ref_name][beat1]*sr)]\n",
    "        base_time = 275465\n",
    "        \n",
    "        new_times = {}\n",
    "        for i in range(idx1,idx2):\n",
    "            key = annotated_beats[i]\n",
    "            sample = tf[int(timeData[ref_name][key]*sr)]\n",
    "            new_time = sample-base_time\n",
    "            new_times[key]=new_time\n",
    "        \n",
    "        gt_beats = list(timeData[solo_name].keys())\n",
    "        gt_base_time=timeData[solo_name][beat1]\n",
    "        for key in new_times:\n",
    "            if key in gt_beats:\n",
    "                gt_time = (timeData[solo_name][key]-gt_base_time)*sr\n",
    "                pred_time = new_times[key]\n",
    "                #print(gt_time/sr, pred_time/sr)\n",
    "                #diffs.append(np.abs(gt_time-pred_time))\n",
    "                beat_array.append((gt_time,pred_time))\n",
    "    \n",
    "        print('here')\n",
    "    beat_ls.append(beat_array)\n",
    "    for i in range(len(beat_ls)):\n",
    "        for j in range(len(beat_ls[i])):\n",
    "            if j>0:\n",
    "                ground_diff = beat_ls[i][j][0]-beat_ls[i][j-1][0]\n",
    "                predict_diff = beat_ls[i][j][1]-beat_ls[i][j-1][1]\n",
    "                diffs.append(np.abs(ground_diff-predict_diff))\n",
    "    \n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateBeatLevel(tf, segment_predict, solo_name, ref_name, sr=22050):\n",
    "    # Only evaluate within segments\n",
    "    diffs = []\n",
    "    pieceName = solo_name.split('_')[0]\n",
    "    gt_segments = queryInfo[pieceName]\n",
    "    annotated_beats = list(timeData[ref_name].keys())\n",
    "    for idx,beats in enumerate(gt_segments):\n",
    "        beat1 = beats.split(',')[0][1:]\n",
    "        beat2 = beats.split(',')[1][:-1]\n",
    "        idx1 = annotated_beats.index(beat1)\n",
    "        idx2 = annotated_beats.index(beat2)\n",
    "        offset = int(timeData[ref_name][beat1]*sr)-segment_predict[idx][0]\n",
    "        base_time = tf[segment_predict[idx][0]]\n",
    "        base_time = tf[int(timeData[ref_name][beat1]*sr)]\n",
    "        #print(offset)\n",
    "        \n",
    "        new_times = {}\n",
    "        for i in range(idx1,idx2+1):\n",
    "            key = annotated_beats[i]\n",
    "            sample = tf[int(timeData[ref_name][key]*sr)]\n",
    "            new_time = sample-base_time\n",
    "            new_times[key]=new_time\n",
    "            \n",
    "        gt_beats = list(timeData[solo_name].keys())\n",
    "        gt_base_time=timeData[solo_name][beat1]\n",
    "        prev = 0\n",
    "        prevgt = 0\n",
    "        for idx, key in enumerate(new_times):\n",
    "            if key in gt_beats:\n",
    "                gt_time = (timeData[solo_name][key]-gt_base_time)*sr\n",
    "                pred_time = new_times[key]\n",
    "                #f idx != 0:\n",
    "                #   print(\"diff\",gt_time-prevgt, pred_time-prev)\n",
    "                prev = pred_time\n",
    "                prevgt = gt_time\n",
    "                #rint(gt_time, pred_time)\n",
    "                diffs.append(np.abs(gt_time-pred_time))\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateBeatLevelFirst(tf, segment_predict, solo_name, ref_name, sr=22050):\n",
    "    # Only evaluate within segments\n",
    "    diffs = []\n",
    "    pieceName = solo_name.split('_')[0]\n",
    "    gt_segments = queryInfo[pieceName]\n",
    "    annotated_beats = list(timeData[ref_name].keys())\n",
    "    for idx,beats in enumerate(gt_segments):\n",
    "        if idx!=0:\n",
    "            continue\n",
    "        beat1 = beats.split(',')[0][1:]\n",
    "        beat2 = beats.split(',')[1][:-1]\n",
    "        idx1 = annotated_beats.index(beat1)\n",
    "        idx2 = annotated_beats.index(beat2)\n",
    "        offset = int(timeData[ref_name][beat1]*sr)-segment_predict[idx][0]\n",
    "        base_time = tf[segment_predict[idx][0]]\n",
    "        base_time = tf[int(timeData[ref_name][beat1]*sr)]\n",
    "        #print(offset)\n",
    "        \n",
    "        new_times = {}\n",
    "        for i in range(idx1,idx2+1):\n",
    "            key = annotated_beats[i]\n",
    "            sample = tf[int(timeData[ref_name][key]*sr)]\n",
    "            new_time = sample-base_time\n",
    "            new_times[key]=new_time\n",
    "            \n",
    "        gt_beats = list(timeData[solo_name].keys())\n",
    "        gt_base_time=timeData[solo_name][beat1]\n",
    "        prev = 0\n",
    "        prevgt = 0\n",
    "        for idx, key in enumerate(new_times):\n",
    "            if key in gt_beats:\n",
    "                gt_time = (timeData[solo_name][key]-gt_base_time)*sr\n",
    "                pred_time = new_times[key]\n",
    "                #f idx != 0:\n",
    "                #   print(\"diff\",gt_time-prevgt, pred_time-prev)\n",
    "                prev = pred_time\n",
    "                prevgt = gt_time\n",
    "                #rint(gt_time, pred_time)\n",
    "                diffs.append(np.abs(gt_time-pred_time))\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(hypdir, sr=22050):\n",
    "    data = readHypFiles(hypdir)\n",
    "    times = []\n",
    "    segment_tolerances =[1,.5, 0.25, 0.125]\n",
    "    segment_total = np.zeros(len(segment_tolerances))\n",
    "    segment_correct = np.zeros(len(segment_tolerances))\n",
    "    \n",
    "    beat_tolerances =np.arange(0.05, 2, 0.05)\n",
    "    beat_total = np.zeros(len(beat_tolerances))\n",
    "    beat_correct = np.zeros(len(beat_tolerances))\n",
    "    beat_totalFirst = np.zeros(len(beat_tolerances))\n",
    "    beat_correctFirst = np.zeros(len(beat_tolerances))\n",
    "    for solo_name, ref_name, tf, segment_predict, time_taken in data:\n",
    "        segment_predict = np.array(segment_predict)*512\n",
    "        #print(segment_predict)\n",
    "        segment_diffs = evaluateSegmentLevel(segment_predict, solo_name, ref_name)\n",
    "        beat_diffs = evaluateBeatLevel(tf, segment_predict, solo_name, ref_name)\n",
    "        beat_diffsFirst = evaluateBeatLevelFirst(tf, segment_predict, solo_name, ref_name)\n",
    "        #beat_diffs = evaluateDiffLevel(tf, segment_predict, solo_name, ref_name)\n",
    "        segment_diffs =np.array(segment_diffs)/sr\n",
    "        beat_diffs =(np.array(beat_diffs)/sr)\n",
    "        beat_diffsFirst =(np.array(beat_diffsFirst)/sr)\n",
    "        times.append(time_taken)\n",
    "        \n",
    "        #Update Segment Level Accuracy\n",
    "        for idx, tolerance in enumerate(segment_tolerances):\n",
    "            segment_correct[idx] += np.sum(np.where(segment_diffs<tolerance, 1, 0))\n",
    "            segment_total[idx]+=len(segment_diffs)\n",
    "            \n",
    "            \n",
    "        #Update Beat Level Accuracy\n",
    "        for idx, tolerance in enumerate(beat_tolerances):\n",
    "            beat_correct[idx] += np.sum(np.where(beat_diffs<tolerance, 1, 0))\n",
    "            beat_total[idx]+=len(beat_diffs)\n",
    "            \n",
    "        #Update First Beat Level Accuracy\n",
    "        for idx, tolerance in enumerate(beat_tolerances):\n",
    "            beat_correctFirst[idx] += np.sum(np.where(beat_diffsFirst<tolerance, 1, 0))\n",
    "            beat_totalFirst[idx]+=len(beat_diffsFirst)\n",
    "    print(segment_correct/segment_total)\n",
    "    print(beat_correct/beat_total)\n",
    "    print(beat_correctFirst/beat_totalFirst)\n",
    "    #print(beat_correct, beat_total)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/debug6/p1s_perf12-p1f_perf16.hyp\n",
      "experiments/debug6/p1s_perf12-p1f_perf2.hyp\n",
      "experiments/debug6/p1s_perf12-p1f_perf23.hyp\n",
      "experiments/debug6/p1s_perf12-p1f_perf24.hyp\n",
      "experiments/debug6/p1s_perf12-p1f_perf6.hyp\n",
      "experiments/debug6/p1s_perf2-p1f_perf16.hyp\n",
      "experiments/debug6/p1s_perf2-p1f_perf2.hyp\n",
      "experiments/debug6/p1s_perf2-p1f_perf23.hyp\n",
      "experiments/debug6/p1s_perf2-p1f_perf24.hyp\n",
      "experiments/debug6/p1s_perf2-p1f_perf6.hyp\n",
      "experiments/debug6/p1s_perf25-p1f_perf16.hyp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-374-03ed9364b97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"debug6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-367-6349130ef07a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(hypdir, sr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadHypFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msegment_tolerances\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.125\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msegment_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_tolerances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bc402d1309b0>\u001b[0m in \u001b[0;36mreadHypFiles\u001b[0;34m(hypdir)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(\"debug6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488723"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr=22050\n",
    "solo_name, ref_name = 'p1s_perf25', 'p1f_perf23'\n",
    "int(timeData[ref_name]['24.1']*sr)-int(timeData[ref_name]['9.1']*sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622280"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(timeData[solo_name]['24.1']*sr)-int(timeData[solo_name]['9.1']*sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1. 1. 1. 1.]\n",
    "[0.06420892 0.09891645 0.12300008 0.14661813 0.16837383 0.18619318\n",
    " 0.20562093 0.22208584 0.23706933 0.24997884 0.26254973 0.27414713\n",
    " 0.2852366  0.29713028 0.30826208 0.31901295 0.32917125 0.33818674\n",
    " 0.34690595 0.35469398 0.3629476  0.37238635 0.38114789 0.38914755\n",
    " 0.39757047 0.40607805 0.41403538 0.42161178 0.42884957 0.43659528\n",
    " 0.44379074 0.4509862  0.45767375 0.46482689 0.4719377  0.47866757\n",
    " 0.4854821  0.49115381 0.49729112]\n",
    "[0.16987665 0.27050422 0.31962779 0.371781   0.4165765  0.44579095\n",
    " 0.47219217 0.48820602 0.49902618 0.50941355 0.51763688 0.5254274\n",
    " 0.53386713 0.54230686 0.5513958  0.55832071 0.56546202 0.57108851\n",
    " 0.57736421 0.5834235  0.5896992  0.5959749  0.60160138 0.60722787\n",
    " 0.61263796 0.61804804 0.62259251 0.62886821 0.63276347 0.63817356\n",
    " 0.64271803 0.64834451 0.653971   0.65981389 0.66327635 0.66825362\n",
    " 0.67474573 0.67712616 0.68231984]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
