{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T22:51:31.327359Z",
     "start_time": "2020-05-09T22:51:30.978322Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import glob\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T22:51:32.026925Z",
     "start_time": "2020-05-09T22:51:31.445617Z"
    }
   },
   "outputs": [],
   "source": [
    "fileId_path = \"experiments/fileIds.pkl\"\n",
    "queryInfo_path = \"experiments/queryInfo.pkl\"\n",
    "timeData_path = \"experiments/timeData.pkl\"\n",
    "audioFiles_path = \"experiments/audioFiles.pkl\"\n",
    "with open(fileId_path, 'rb') as f:\n",
    "    fileIds=pkl.load(f)\n",
    "with open(queryInfo_path, 'rb') as f:\n",
    "    queryInfo=pkl.load(f)\n",
    "with open(timeData_path, 'rb') as f:\n",
    "    timeData=pkl.load(f)\n",
    "with open(audioFiles_path, 'rb') as f:\n",
    "    audioFiles=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T22:51:32.031812Z",
     "start_time": "2020-05-09T22:51:32.028767Z"
    }
   },
   "outputs": [],
   "source": [
    "def readHypFiles(hypdir):\n",
    "    \n",
    "    for hypfile in sorted(glob.glob(\"{}/*.hyp\".format(hypdir))):\n",
    "        print(hypfile)\n",
    "        with open(hypfile, \"rb\") as f:\n",
    "            yield(pkl.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T22:51:32.216203Z",
     "start_time": "2020-05-09T22:51:32.207075Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluateBeatLevel(tf, solo_name, ref_name, sr=22050):\n",
    "    # Only evaluate within segments\n",
    "    diffs = []\n",
    "    pieceName = solo_name.split('_')[0]\n",
    "    gt_segments = queryInfo[pieceName]\n",
    "    annotated_beats = list(timeData[ref_name].keys())\n",
    "    for idx,beats in enumerate(gt_segments):\n",
    "        beat1 = beats.split(',')[0][1:]\n",
    "        beat2 = beats.split(',')[1][:-1]\n",
    "        idx1 = annotated_beats.index(beat1)\n",
    "        idx2 = annotated_beats.index(beat2)\n",
    "        #offset = int(timeData[ref_name][beat1]*sr)-segment_predict[idx][0]\n",
    "        #base_time = tf[segment_predict[idx][0]]\n",
    "        base_time = tf[int(timeData[ref_name][beat1]*sr)]\n",
    "        #print(offset)\n",
    "        \n",
    "        new_times = {}\n",
    "        for i in range(idx1,idx2+1):\n",
    "            key = annotated_beats[i]\n",
    "            sample = tf[int(timeData[ref_name][key]*sr)]\n",
    "            new_time = sample-base_time\n",
    "            new_times[key]=new_time\n",
    "            \n",
    "        gt_beats = list(timeData[solo_name].keys())\n",
    "        gt_base_time=timeData[solo_name][beat1]\n",
    "        prev = 0\n",
    "        prevgt = 0\n",
    "        for idx, key in enumerate(new_times):\n",
    "            if key in gt_beats:\n",
    "                gt_time = (timeData[solo_name][key]-gt_base_time)*sr\n",
    "                pred_time = new_times[key]\n",
    "                #f idx != 0:\n",
    "                #   print(\"diff\",gt_time-prevgt, pred_time-prev)\n",
    "                prev = pred_time\n",
    "                prevgt = gt_time\n",
    "                #rint(gt_time, pred_time)\n",
    "                diffs.append(np.abs(gt_time-pred_time))\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T22:51:32.564345Z",
     "start_time": "2020-05-09T22:51:32.552985Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluateBeatLevelFirst(tf, segment_predict, solo_name, ref_name, sr=22050):\n",
    "    # Only evaluate within segments\n",
    "    diffs = []\n",
    "    pieceName = solo_name.split('_')[0]\n",
    "    gt_segments = queryInfo[pieceName]\n",
    "    annotated_beats = list(timeData[ref_name].keys())\n",
    "    for idx,beats in enumerate(gt_segments):\n",
    "        if idx!=1:\n",
    "            continue\n",
    "        beat1 = beats.split(',')[0][1:]\n",
    "        beat2 = beats.split(',')[1][:-1]\n",
    "        idx1 = annotated_beats.index(beat1)\n",
    "        idx2 = annotated_beats.index(beat2)\n",
    "        offset = int(timeData[ref_name][beat1]*sr)-segment_predict[idx][0]\n",
    "        base_time = tf[segment_predict[idx][0]]\n",
    "        \n",
    "        new_times = {}\n",
    "        for i in range(idx1,idx2+1):\n",
    "            key = annotated_beats[i]\n",
    "            sample = tf[int(timeData[ref_name][key]*sr)]\n",
    "            new_time = sample-base_time\n",
    "            new_times[key]=new_time\n",
    "            \n",
    "        gt_beats = list(timeData[solo_name].keys())\n",
    "        gt_base_time=timeData[solo_name][beat1]\n",
    "        prev = 0\n",
    "        prevgt = 0\n",
    "        for idx, key in enumerate(new_times):\n",
    "            if key in gt_beats:\n",
    "                gt_time = (timeData[solo_name][key]-gt_base_time)*sr\n",
    "                pred_time = new_times[key]\n",
    "                #f idx != 0:\n",
    "                #   print(\"diff\",gt_time-prevgt, pred_time-prev)\n",
    "                prev = pred_time\n",
    "                prevgt = gt_time\n",
    "                #rint(gt_time, pred_time)\n",
    "                diffs.append(np.abs(gt_time-pred_time))\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T22:51:32.837998Z",
     "start_time": "2020-05-09T22:51:32.831186Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluateSegmentLevel(segment_predict, solo_name, ref_name, sr=22050):\n",
    "    pieceName = solo_name.split('_')[0]\n",
    "    gt_segments = queryInfo[pieceName]\n",
    "    gt_samples = []\n",
    "    diffs = []\n",
    "    for beats in gt_segments:\n",
    "        beat1 = beats.split(',')[0][1:]\n",
    "        beat2 = beats.split(',')[1][:-1]\n",
    "        sample1 = timeData[ref_name][beat1]*sr\n",
    "        sample2 = timeData[ref_name][beat2]*sr\n",
    "        gt_samples.append((sample1, sample2))\n",
    "    for idx,segment in enumerate(segment_predict):\n",
    "        seg0 = segment[0]\n",
    "        seg1 = segment[1]\n",
    "        diff0 = np.abs(gt_samples[idx][0]-seg0)\n",
    "        diff1 = np.abs(gt_samples[idx][1]-seg1)\n",
    "        diffs.append(diff0)\n",
    "        diffs.append(diff1)\n",
    "        if diff0 > 22050:\n",
    "            print(solo_name, ref_name)\n",
    "            print(gt_samples[idx][0],seg0)\n",
    "        if diff1 > 22050:\n",
    "            print(ref_name, solo_name)\n",
    "            print(gt_samples[idx][1],seg1)\n",
    "        #print((gt_samples[idx][0]-seg0)/(sr*sr))\n",
    "    return diffs, gt_samples, segment_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T05:38:25.652697Z",
     "start_time": "2020-05-10T05:38:25.633766Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(hypdir, hop_length=512, sr=22050):\n",
    "    \n",
    "    times = []\n",
    "    segment_tolerances =[1, 0.5, 0.25]\n",
    "    segment_total = np.zeros(len(segment_tolerances))\n",
    "    segment_correct = np.zeros(len(segment_tolerances))\n",
    "    \n",
    "    beat_tolerances =np.arange(0.0, 2, 0.025)\n",
    "    #beat_tolerances=[0.25]\n",
    "    beat_total = np.zeros(len(beat_tolerances))\n",
    "    beat_correct = np.zeros(len(beat_tolerances))\n",
    "    beat_totalFirst = np.zeros(len(beat_tolerances))\n",
    "    beat_correctFirst = np.zeros(len(beat_tolerances))\n",
    "    for solo_name, ref_name, tf, segment_predict, time_taken in readHypFiles(hypdir):\n",
    "        tf = np.array(tf)\n",
    "        segment_predict = np.array(segment_predict)*hop_length\n",
    "        #print(segment_predict)\n",
    "        segment_diffs, gt_samples, segment_predict = evaluateSegmentLevel(segment_predict, solo_name, ref_name)\n",
    "        if any(tf!=None):\n",
    "            beat_diffs = evaluateBeatLevel(tf, solo_name, ref_name)\n",
    "            beat_diffsFirst = evaluateBeatLevelFirst(tf, segment_predict, solo_name, ref_name)\n",
    "            #beat_diffs = evaluateDiffLevel(tf, segment_predict, solo_name, ref_name)\n",
    "            beat_diffs =(np.array(beat_diffs)/sr)\n",
    "            beat_diffsFirst =(np.array(beat_diffsFirst)/sr)\n",
    "        segment_diffs =np.array(segment_diffs)/sr\n",
    "        times.append(time_taken)\n",
    "        \n",
    "        #Update Segment Level Accuracy\n",
    "        for idx, tolerance in enumerate(segment_tolerances):\n",
    "            segment_correct[idx] += np.sum(np.where(segment_diffs<tolerance, 1, 0))\n",
    "            segment_total[idx]+=len(segment_diffs)\n",
    "            \n",
    "            \n",
    "        if any(tf!=None):\n",
    "            #Update Beat Level Accuracy\n",
    "            for idx, tolerance in enumerate(beat_tolerances):\n",
    "                beat_correct[idx] += np.sum(np.where(beat_diffs<tolerance, 1, 0))\n",
    "                beat_total[idx]+=len(beat_diffs)\n",
    "\n",
    "            #Update First Beat Level Accuracy\n",
    "            for idx, tolerance in enumerate(beat_tolerances):\n",
    "                beat_correctFirst[idx] += np.sum(np.where(beat_diffsFirst<tolerance, 1, 0))\n",
    "                beat_totalFirst[idx]+=len(beat_diffsFirst)\n",
    "    print(\"hop_length\", hop_length)\n",
    "    print(segment_correct/segment_total)\n",
    "    print(beat_correct/beat_total)\n",
    "    return segment_correct/segment_total, beat_correct/beat_total, times   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T22:54:26.822684Z",
     "start_time": "2020-05-09T22:53:55.892781Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_accuracy, beat_accuracy, times = evaluate(\"experiments/expFinal\", hop_length=512)\n",
    "#seg_accuracy, beat_accuracy = evaluate(\"baselines/debug2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
